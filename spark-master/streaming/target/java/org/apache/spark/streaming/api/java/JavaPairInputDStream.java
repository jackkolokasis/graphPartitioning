package org.apache.spark.streaming.api.java;
/**
 * A Java-friendly interface to {@link org.apache.spark.streaming.dstream.InputDStream} of
 * key-value pairs.
 */
public  class JavaPairInputDStream<K extends java.lang.Object, V extends java.lang.Object> extends org.apache.spark.streaming.api.java.JavaPairDStream<K, V> {
  /**
   * Convert a scala {@link org.apache.spark.streaming.dstream.InputDStream} of pairs to a
   * Java-friendly {@link org.apache.spark.streaming.api.java.JavaPairInputDStream}.
   * @param inputDStream (undocumented)
   * @param evidence$1 (undocumented)
   * @param evidence$2 (undocumented)
   * @return (undocumented)
   */
  static public <K extends java.lang.Object, V extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairInputDStream<K, V> fromInputDStream (org.apache.spark.streaming.dstream.InputDStream<scala.Tuple2<K, V>> inputDStream, scala.reflect.ClassTag<K> evidence$1, scala.reflect.ClassTag<V> evidence$2)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<java.lang.Long> scalaIntToJavaLong (org.apache.spark.streaming.dstream.DStream<java.lang.Object> in)  { throw new RuntimeException(); }
  static public  void print ()  { throw new RuntimeException(); }
  static public  void print (int num)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<java.lang.Long> count ()  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<T, java.lang.Long> countByValue ()  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<T, java.lang.Long> countByValue (int numPartitions)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<java.lang.Long> countByWindow (org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<T, java.lang.Long> countByValueAndWindow (org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<T, java.lang.Long> countByValueAndWindow (org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration, int numPartitions)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<java.util.List<T>> glom ()  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.StreamingContext context ()  { throw new RuntimeException(); }
  static public <R extends java.lang.Object> org.apache.spark.streaming.api.java.JavaDStream<R> map (org.apache.spark.api.java.function.Function<T, R> f)  { throw new RuntimeException(); }
  static public <K2 extends java.lang.Object, V2 extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> mapToPair (org.apache.spark.api.java.function.PairFunction<T, K2, V2> f)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object> org.apache.spark.streaming.api.java.JavaDStream<U> flatMap (org.apache.spark.api.java.function.FlatMapFunction<T, U> f)  { throw new RuntimeException(); }
  static public <K2 extends java.lang.Object, V2 extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> flatMapToPair (org.apache.spark.api.java.function.PairFlatMapFunction<T, K2, V2> f)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object> org.apache.spark.streaming.api.java.JavaDStream<U> mapPartitions (org.apache.spark.api.java.function.FlatMapFunction<java.util.Iterator<T>, U> f)  { throw new RuntimeException(); }
  static public <K2 extends java.lang.Object, V2 extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> mapPartitionsToPair (org.apache.spark.api.java.function.PairFlatMapFunction<java.util.Iterator<T>, K2, V2> f)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<T> reduce (org.apache.spark.api.java.function.Function2<T, T, T> f)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<T> reduceByWindow (org.apache.spark.api.java.function.Function2<T, T, T> reduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<T> reduceByWindow (org.apache.spark.api.java.function.Function2<T, T, T> reduceFunc, org.apache.spark.api.java.function.Function2<T, T, T> invReduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  java.util.List<R> slice (org.apache.spark.streaming.Time fromTime, org.apache.spark.streaming.Time toTime)  { throw new RuntimeException(); }
  static public  void foreachRDD (org.apache.spark.api.java.function.VoidFunction<R> foreachFunc)  { throw new RuntimeException(); }
  static public  void foreachRDD (org.apache.spark.api.java.function.VoidFunction2<R, org.apache.spark.streaming.Time> foreachFunc)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object> org.apache.spark.streaming.api.java.JavaDStream<U> transform (org.apache.spark.api.java.function.Function<R, org.apache.spark.api.java.JavaRDD<U>> transformFunc)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object> org.apache.spark.streaming.api.java.JavaDStream<U> transform (org.apache.spark.api.java.function.Function2<R, org.apache.spark.streaming.Time, org.apache.spark.api.java.JavaRDD<U>> transformFunc)  { throw new RuntimeException(); }
  static public <K2 extends java.lang.Object, V2 extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> transformToPair (org.apache.spark.api.java.function.Function<R, org.apache.spark.api.java.JavaPairRDD<K2, V2>> transformFunc)  { throw new RuntimeException(); }
  static public <K2 extends java.lang.Object, V2 extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> transformToPair (org.apache.spark.api.java.function.Function2<R, org.apache.spark.streaming.Time, org.apache.spark.api.java.JavaPairRDD<K2, V2>> transformFunc)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object, W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaDStream<W> transformWith (org.apache.spark.streaming.api.java.JavaDStream<U> other, org.apache.spark.api.java.function.Function3<R, org.apache.spark.api.java.JavaRDD<U>, org.apache.spark.streaming.Time, org.apache.spark.api.java.JavaRDD<W>> transformFunc)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object, K2 extends java.lang.Object, V2 extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> transformWithToPair (org.apache.spark.streaming.api.java.JavaDStream<U> other, org.apache.spark.api.java.function.Function3<R, org.apache.spark.api.java.JavaRDD<U>, org.apache.spark.streaming.Time, org.apache.spark.api.java.JavaPairRDD<K2, V2>> transformFunc)  { throw new RuntimeException(); }
  static public <K2 extends java.lang.Object, V2 extends java.lang.Object, W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaDStream<W> transformWith (org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> other, org.apache.spark.api.java.function.Function3<R, org.apache.spark.api.java.JavaPairRDD<K2, V2>, org.apache.spark.streaming.Time, org.apache.spark.api.java.JavaRDD<W>> transformFunc)  { throw new RuntimeException(); }
  static public <K2 extends java.lang.Object, V2 extends java.lang.Object, K3 extends java.lang.Object, V3 extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K3, V3> transformWithToPair (org.apache.spark.streaming.api.java.JavaPairDStream<K2, V2> other, org.apache.spark.api.java.function.Function3<R, org.apache.spark.api.java.JavaPairRDD<K2, V2>, org.apache.spark.streaming.Time, org.apache.spark.api.java.JavaPairRDD<K3, V3>> transformFunc)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.dstream.DStream<T> checkpoint (org.apache.spark.streaming.Duration interval)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.dstream.DStream<scala.Tuple2<K, V>> dstream ()  { throw new RuntimeException(); }
  static public  scala.reflect.ClassTag<K> kManifest ()  { throw new RuntimeException(); }
  static public  scala.reflect.ClassTag<V> vManifest ()  { throw new RuntimeException(); }
  static public  org.apache.spark.api.java.JavaPairRDD<K, V> wrapRDD (org.apache.spark.rdd.RDD<scala.Tuple2<K, V>> rdd)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> filter (org.apache.spark.api.java.function.Function<scala.Tuple2<K, V>, java.lang.Boolean> f)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> cache ()  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> persist ()  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> persist (org.apache.spark.storage.StorageLevel storageLevel)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> repartition (int numPartitions)  { throw new RuntimeException(); }
  static public  org.apache.spark.api.java.JavaPairRDD<K, V> compute (org.apache.spark.streaming.Time validTime)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> window (org.apache.spark.streaming.Duration windowDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> window (org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> union (org.apache.spark.streaming.api.java.JavaPairDStream<K, V> that)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, java.lang.Iterable<V>> groupByKey ()  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, java.lang.Iterable<V>> groupByKey (int numPartitions)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, java.lang.Iterable<V>> groupByKey (org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKey (org.apache.spark.api.java.function.Function2<V, V, V> func)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKey (org.apache.spark.api.java.function.Function2<V, V, V> func, int numPartitions)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKey (org.apache.spark.api.java.function.Function2<V, V, V> func, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public <C extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, C> combineByKey (org.apache.spark.api.java.function.Function<V, C> createCombiner, org.apache.spark.api.java.function.Function2<C, V, C> mergeValue, org.apache.spark.api.java.function.Function2<C, C, C> mergeCombiners, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public <C extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, C> combineByKey (org.apache.spark.api.java.function.Function<V, C> createCombiner, org.apache.spark.api.java.function.Function2<C, V, C> mergeValue, org.apache.spark.api.java.function.Function2<C, C, C> mergeCombiners, org.apache.spark.Partitioner partitioner, boolean mapSideCombine)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, java.lang.Iterable<V>> groupByKeyAndWindow (org.apache.spark.streaming.Duration windowDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, java.lang.Iterable<V>> groupByKeyAndWindow (org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, java.lang.Iterable<V>> groupByKeyAndWindow (org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration, int numPartitions)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, java.lang.Iterable<V>> groupByKeyAndWindow (org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKeyAndWindow (org.apache.spark.api.java.function.Function2<V, V, V> reduceFunc, org.apache.spark.streaming.Duration windowDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKeyAndWindow (org.apache.spark.api.java.function.Function2<V, V, V> reduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKeyAndWindow (org.apache.spark.api.java.function.Function2<V, V, V> reduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration, int numPartitions)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKeyAndWindow (org.apache.spark.api.java.function.Function2<V, V, V> reduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKeyAndWindow (org.apache.spark.api.java.function.Function2<V, V, V> reduceFunc, org.apache.spark.api.java.function.Function2<V, V, V> invReduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKeyAndWindow (org.apache.spark.api.java.function.Function2<V, V, V> reduceFunc, org.apache.spark.api.java.function.Function2<V, V, V> invReduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration, int numPartitions, org.apache.spark.api.java.function.Function<scala.Tuple2<K, V>, java.lang.Boolean> filterFunc)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaPairDStream<K, V> reduceByKeyAndWindow (org.apache.spark.api.java.function.Function2<V, V, V> reduceFunc, org.apache.spark.api.java.function.Function2<V, V, V> invReduceFunc, org.apache.spark.streaming.Duration windowDuration, org.apache.spark.streaming.Duration slideDuration, org.apache.spark.Partitioner partitioner, org.apache.spark.api.java.function.Function<scala.Tuple2<K, V>, java.lang.Boolean> filterFunc)  { throw new RuntimeException(); }
  static public <StateType extends java.lang.Object, MappedType extends java.lang.Object> org.apache.spark.streaming.api.java.JavaMapWithStateDStream<K, V, StateType, MappedType> mapWithState (org.apache.spark.streaming.StateSpec<K, V, StateType, MappedType> spec)  { throw new RuntimeException(); }
  static public <S extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, S> updateStateByKey (org.apache.spark.api.java.function.Function2<java.util.List<V>, org.apache.spark.api.java.Optional<S>, org.apache.spark.api.java.Optional<S>> updateFunc)  { throw new RuntimeException(); }
  static public <S extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, S> updateStateByKey (org.apache.spark.api.java.function.Function2<java.util.List<V>, org.apache.spark.api.java.Optional<S>, org.apache.spark.api.java.Optional<S>> updateFunc, int numPartitions)  { throw new RuntimeException(); }
  static public <S extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, S> updateStateByKey (org.apache.spark.api.java.function.Function2<java.util.List<V>, org.apache.spark.api.java.Optional<S>, org.apache.spark.api.java.Optional<S>> updateFunc, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public <S extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, S> updateStateByKey (org.apache.spark.api.java.function.Function2<java.util.List<V>, org.apache.spark.api.java.Optional<S>, org.apache.spark.api.java.Optional<S>> updateFunc, org.apache.spark.Partitioner partitioner, org.apache.spark.api.java.JavaPairRDD<K, S> initialRDD)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, U> mapValues (org.apache.spark.api.java.function.Function<V, U> f)  { throw new RuntimeException(); }
  static public <U extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, U> flatMapValues (org.apache.spark.api.java.function.Function<V, java.lang.Iterable<U>> f)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<java.lang.Iterable<V>, java.lang.Iterable<W>>> cogroup (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<java.lang.Iterable<V>, java.lang.Iterable<W>>> cogroup (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, int numPartitions)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<java.lang.Iterable<V>, java.lang.Iterable<W>>> cogroup (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<V, W>> join (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<V, W>> join (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, int numPartitions)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<V, W>> join (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<V, org.apache.spark.api.java.Optional<W>>> leftOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<V, org.apache.spark.api.java.Optional<W>>> leftOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, int numPartitions)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<V, org.apache.spark.api.java.Optional<W>>> leftOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<org.apache.spark.api.java.Optional<V>, W>> rightOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<org.apache.spark.api.java.Optional<V>, W>> rightOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, int numPartitions)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<org.apache.spark.api.java.Optional<V>, W>> rightOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<org.apache.spark.api.java.Optional<V>, org.apache.spark.api.java.Optional<W>>> fullOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<org.apache.spark.api.java.Optional<V>, org.apache.spark.api.java.Optional<W>>> fullOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, int numPartitions)  { throw new RuntimeException(); }
  static public <W extends java.lang.Object> org.apache.spark.streaming.api.java.JavaPairDStream<K, scala.Tuple2<org.apache.spark.api.java.Optional<V>, org.apache.spark.api.java.Optional<W>>> fullOuterJoin (org.apache.spark.streaming.api.java.JavaPairDStream<K, W> other, org.apache.spark.Partitioner partitioner)  { throw new RuntimeException(); }
  static public  void saveAsHadoopFiles (java.lang.String prefix, java.lang.String suffix)  { throw new RuntimeException(); }
  static public <F extends org.apache.hadoop.mapred.OutputFormat<?, ?>> void saveAsHadoopFiles (java.lang.String prefix, java.lang.String suffix, java.lang.Class<?> keyClass, java.lang.Class<?> valueClass, java.lang.Class<F> outputFormatClass)  { throw new RuntimeException(); }
  static public <F extends org.apache.hadoop.mapred.OutputFormat<?, ?>> void saveAsHadoopFiles (java.lang.String prefix, java.lang.String suffix, java.lang.Class<?> keyClass, java.lang.Class<?> valueClass, java.lang.Class<F> outputFormatClass, org.apache.hadoop.mapred.JobConf conf)  { throw new RuntimeException(); }
  static public  void saveAsNewAPIHadoopFiles (java.lang.String prefix, java.lang.String suffix)  { throw new RuntimeException(); }
  static public <F extends org.apache.hadoop.mapreduce.OutputFormat<?, ?>> void saveAsNewAPIHadoopFiles (java.lang.String prefix, java.lang.String suffix, java.lang.Class<?> keyClass, java.lang.Class<?> valueClass, java.lang.Class<F> outputFormatClass)  { throw new RuntimeException(); }
  static public <F extends org.apache.hadoop.mapreduce.OutputFormat<?, ?>> void saveAsNewAPIHadoopFiles (java.lang.String prefix, java.lang.String suffix, java.lang.Class<?> keyClass, java.lang.Class<?> valueClass, java.lang.Class<F> outputFormatClass, org.apache.hadoop.conf.Configuration conf)  { throw new RuntimeException(); }
  static public  org.apache.spark.streaming.api.java.JavaDStream<scala.Tuple2<K, V>> toJavaDStream ()  { throw new RuntimeException(); }
  static public  scala.reflect.ClassTag<scala.Tuple2<K, V>> classTag ()  { throw new RuntimeException(); }
  static public <F extends org.apache.hadoop.mapreduce.OutputFormat<?, ?>> org.apache.hadoop.conf.Configuration saveAsNewAPIHadoopFiles$default$6 ()  { throw new RuntimeException(); }
  public  org.apache.spark.streaming.dstream.InputDStream<scala.Tuple2<K, V>> inputDStream ()  { throw new RuntimeException(); }
  public  scala.reflect.ClassTag<K> kClassTag ()  { throw new RuntimeException(); }
  public  scala.reflect.ClassTag<V> vClassTag ()  { throw new RuntimeException(); }
  // not preceding
  public   JavaPairInputDStream (org.apache.spark.streaming.dstream.InputDStream<scala.Tuple2<K, V>> inputDStream, scala.reflect.ClassTag<K> kClassTag, scala.reflect.ClassTag<V> vClassTag)  { throw new RuntimeException(); }
}
