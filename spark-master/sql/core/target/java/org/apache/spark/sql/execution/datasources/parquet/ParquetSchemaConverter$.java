package org.apache.spark.sql.execution.datasources.parquet;
public  class ParquetSchemaConverter$ {
  /**
   * Static reference to the singleton instance of this Scala object.
   */
  public static final ParquetSchemaConverter$ MODULE$ = null;
  public   ParquetSchemaConverter$ ()  { throw new RuntimeException(); }
  public  java.lang.String SPARK_PARQUET_SCHEMA_NAME ()  { throw new RuntimeException(); }
  public  org.apache.parquet.schema.MessageType EMPTY_MESSAGE ()  { throw new RuntimeException(); }
  public  void checkFieldName (java.lang.String name)  { throw new RuntimeException(); }
  public  org.apache.spark.sql.types.StructType checkFieldNames (org.apache.spark.sql.types.StructType schema)  { throw new RuntimeException(); }
  public  void checkConversionRequirement (scala.Function0<java.lang.Object> f, java.lang.String message)  { throw new RuntimeException(); }
  private  int computeMinBytesForPrecision (int precision)  { throw new RuntimeException(); }
  public  int[] minBytesForPrecision ()  { throw new RuntimeException(); }
  public  int maxPrecisionForBytes (int numBytes)  { throw new RuntimeException(); }
}
